{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "import io, os, wave\n",
    "import assemblyai as aai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert MP3/M4A to PCM S16LE format\n",
    "def convert_audio_to_pcm_s16le(file_path):\n",
    "    print(f\"Converting {file_path} to PCM S16LE format...\")\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)  # 16-bit, mono, 16kHz\n",
    "    buffer = io.BytesIO()\n",
    "    audio.export(buffer, format=\"raw\")\n",
    "    print(\"Conversion completed.\")\n",
    "    return buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert MP3/M4A to PCM MULAW format\n",
    "def convert_audio_to_mulaw(file_path):\n",
    "    print(f\"Converting {file_path} to PCM MULAW format...\")\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    audio = audio.set_frame_rate(8000).set_channels(1).set_sample_width(2)\n",
    "    buffer = io.BytesIO()\n",
    "    audio.export(buffer, format=\"wav\")\n",
    "    print(\"Conversion completed.\")\n",
    "    return buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_audio_pcm(audio_data, sample_rate=16000, channels=1, sample_width=2):\n",
    "    with io.BytesIO(audio_data) as audio_file:\n",
    "        with wave.open(audio_file, \"rb\") as wf:\n",
    "            print(f\"Audio format: {wf.getnchannels()} channel(s), {wf.getframerate()} Hz, {wf.getsampwidth()} byte(s) per sample\")\n",
    "            assert wf.getnchannels() == channels, \"Audio is not mono\"\n",
    "            assert wf.getframerate() == sample_rate, f\"Sample rate is not {sample_rate} Hz\"\n",
    "            assert wf.getsampwidth() == sample_width, f\"Sample width is not {sample_width} bytes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to verify audio format\n",
    "def verify_audio_mulaw(audio_data):\n",
    "    with io.BytesIO(audio_data) as audio_file:\n",
    "        with wave.open(audio_file, \"rb\") as wf:\n",
    "            print(f\"Audio format: {wf.getnchannels()} channel(s), {wf.getframerate()} Hz, {wf.getsampwidth()} byte(s) per sample\")\n",
    "            assert wf.getnchannels() == 1, \"Audio is not mono\"\n",
    "            assert wf.getframerate() == 8000, \"Sample rate is not 8kHz\"\n",
    "            assert wf.getsampwidth() == 2, \"Sample width is not 16-bit PCM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"ASSEMBLYAI_API_KEY not set in .env file\")\n",
    "aai.settings.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_audio_realtime(audio_data, sample_rate:int = 8000, mulaw_encoding:bool = True):\n",
    "    \"\"\"\n",
    "    Stream audio data in chunks to AssemblyAI for realtime transcription.\n",
    "    \"\"\"\n",
    "    final_transcripts = []\n",
    "    session_opened = False\n",
    "\n",
    "    # Define callback functions\n",
    "    def on_open(session_opened_event: aai.RealtimeSessionOpened):\n",
    "        nonlocal session_opened\n",
    "        session_opened = True\n",
    "        print(\"Realtime session opened:\", session_opened_event.session_id)\n",
    "\n",
    "    def on_data(transcript: aai.RealtimeTranscript):\n",
    "        if isinstance(transcript, aai.RealtimeFinalTranscript):\n",
    "            final_transcripts.append(transcript.text)\n",
    "            print(\"Final:\", transcript.text)\n",
    "        else:\n",
    "            print(\"Partial:\", transcript.text)\n",
    "\n",
    "    def on_error(error: aai.RealtimeError):\n",
    "        print(\"Realtime transcription error:\", error)\n",
    "\n",
    "    def on_close():\n",
    "        print(\"Realtime transcription session closed.\")\n",
    "\n",
    "    # Create realtime transcriber\n",
    "    transcriber = aai.RealtimeTranscriber(\n",
    "        sample_rate=sample_rate,\n",
    "        on_open=on_open,\n",
    "        on_data=on_data,\n",
    "        on_error=on_error,\n",
    "        on_close=on_close,\n",
    "        encoding=aai.AudioEncoding.pcm_mulaw\n",
    "    )\n",
    "    transcriber.connect()\n",
    "\n",
    "    # Wait for the session to be opened\n",
    "    print(\"Waiting for the session to open...\")\n",
    "    while not session_opened:\n",
    "        pass  # Busy wait; ideally use threading.Event\n",
    "\n",
    "    # Define a generator for audio chunks\n",
    "    def audio_generator():\n",
    "        chunk_size = 3200  # 200ms of audio at 8kHz\n",
    "        for i in range(0, len(audio_data), chunk_size):\n",
    "            chunk = audio_data[i:i + chunk_size]\n",
    "            print(f\"Yielding chunk {i // chunk_size + 1}, size={len(chunk)} bytes\")\n",
    "            yield chunk\n",
    "\n",
    "    # Stream the audio chunks\n",
    "    print(\"Streaming audio chunks...\")\n",
    "    try:\n",
    "        transcriber.stream(audio_generator())\n",
    "    except Exception as e:\n",
    "        print(\"Error during streaming:\", e)\n",
    "    finally:\n",
    "        transcriber.close()\n",
    "\n",
    "    return \"\\n\".join(final_transcripts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Untitled.m4a to PCM MULAW format...\n",
      "Conversion completed.\n",
      "Audio format: 1 channel(s), 8000 Hz, 2 byte(s) per sample\n"
     ]
    }
   ],
   "source": [
    "# Test the Methods\n",
    "audio_path = \"Untitled.m4a\"  # Replace with your audio file path\n",
    "try:\n",
    "    audio_data = convert_audio_to_mulaw(audio_path)\n",
    "    verify_audio_format(audio_data)\n",
    "except Exception as e:\n",
    "    print(\"Error during audio conversion or verification:\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Realtime Transcription ----\n",
      "Waiting for the session to open...\n",
      "Realtime session opened: 684a4a77-7adf-49cf-a81b-5ea6b0d5a1c7\n",
      "Streaming audio chunks...\n",
      "Yielding chunk 1, size=3200 bytes\n",
      "Yielding chunk 2, size=3200 bytes\n",
      "Yielding chunk 3, size=3200 bytes\n",
      "Yielding chunk 4, size=3200 bytes\n",
      "Yielding chunk 5, size=3200 bytes\n",
      "Yielding chunk 6, size=3200 bytes\n",
      "Yielding chunk 7, size=3200 bytes\n",
      "Yielding chunk 8, size=3200 bytes\n",
      "Yielding chunk 9, size=3200 bytes\n",
      "Yielding chunk 10, size=3200 bytes\n",
      "Yielding chunk 11, size=3200 bytes\n",
      "Yielding chunk 12, size=3052 bytes\n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Partial: \n",
      "Realtime transcription session closed.\n",
      "Final Realtime Transcription Result: \n"
     ]
    }
   ],
   "source": [
    "# Realtime Transcription Test\n",
    "print(\"\\n---- Realtime Transcription ----\")\n",
    "try:\n",
    "    realtime_transcription = stream_audio_realtime(audio_data)\n",
    "    print(\"Final Realtime Transcription Result:\", realtime_transcription)\n",
    "except Exception as e:\n",
    "    print(\"Error during transcription:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twilio-twoway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
